{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac46024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished! Total books: 1000\n",
      "                                                 Title   Price Availability  \\\n",
      "308                   Eligible (The Austen Project #4)  £27.09     In stock   \n",
      "436  If I Gave You God's Phone Number....: Searchin...  £20.91     In stock   \n",
      "799              One for the Money (Stephanie Plum #1)  £32.87     In stock   \n",
      "691                                       'Salem's Lot  £49.56     In stock   \n",
      "508              The Bourne Identity (Jason Bourne #1)  £42.78     In stock   \n",
      "\n",
      "    Star Rating  \n",
      "308       Three  \n",
      "436         One  \n",
      "799         Two  \n",
      "691        Four  \n",
      "508        Four  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL_PATTERN = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "all_books = []\n",
    "\n",
    "for pg in range(1, 51): \n",
    "    page_url = URL_PATTERN.format(pg)\n",
    "    response = requests.get(page_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Page {pg} could not be loaded.\")\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    for book in soup.select(\"article.product_pod\"):\n",
    "        book_title = book.h3.a[\"title\"]\n",
    "        book_price = book.select_one(\"p.price_color\").text.strip()\n",
    "        stock_status = book.select_one(\"p.instock.availability\").get_text(strip=True)\n",
    "        \n",
    "        rating_tag = book.select_one(\"p.star-rating\")\n",
    "        star_text = [c for c in rating_tag[\"class\"] if c != \"star-rating\"][0]\n",
    "\n",
    "        all_books.append({\n",
    "            \"Title\": book_title,\n",
    "            \"Price\": book_price,\n",
    "            \"Availability\": stock_status,\n",
    "            \"Star Rating\": star_text\n",
    "        })\n",
    "df = pd.DataFrame(all_books)\n",
    "df.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "print(\"Scraping finished! Total books:\", len(df))\n",
    "print(df.sample(5)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f46044e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import random\n",
    "import tempfile\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(f\"--user-data-dir={tempfile.mkdtemp()}\")\n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\")\n",
    "options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.imdb.com/chart/top/\")\n",
    "time.sleep(random.uniform(3, 5))\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "movies = []\n",
    "for rank, row in enumerate(soup.select(\"li.ipc-metadata-list-summary-item\")[:250], 1):\n",
    "    title_elem = row.select_one(\"h3.ipc-title__text\")\n",
    "    title = title_elem.text.split('.', 1)[1].strip() if title_elem and '.' in title_elem.text else \"N/A\"\n",
    "    year_elem = row.select_one(\"span.sc-b0691f29-8, span.cli-title-metadata-item\")\n",
    "    year = year_elem.text.strip(\"()\") if year_elem else \"N/A\"\n",
    "    rating_elem = row.select_one(\"span.ipc-rating-star--rating\")\n",
    "    rating = rating_elem.text if rating_elem else \"N/A\"\n",
    "    movies.append([rank, title, year, rating])\n",
    "\n",
    "pd.DataFrame(movies, columns=[\"Rank\", \"Title\", \"Year\", \"Rating\"]).to_csv(\"imdb_top250.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c963b15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 city links\n",
      "Scraped weather data for 3 cities.\n",
      "                               City Temperature          Condition\n",
      "0    in Bhubaneshwar, Odisha, India       34 °C  Scattered clouds.\n",
      "1         in Gangtok, Sikkim, India        7 °C        Quite cool.\n",
      "2  in Courtallam, Tamil Nadu, India       31 °C  Scattered clouds.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36\"\n",
    "}\n",
    "\n",
    "base_url = \"https://www.timeanddate.com\"\n",
    "start_url = f\"{base_url}/weather/india\"\n",
    "\n",
    "resp = requests.get(start_url, headers=headers)\n",
    "soup = BeautifulSoup(resp.content, \"html.parser\")\n",
    "\n",
    "city_links = []\n",
    "for a in soup.select(\"section tbody tr td a\"):\n",
    "    href = a.get(\"href\")\n",
    "    if href and href.startswith(\"/weather/india/\"):\n",
    "        city_links.append(base_url + href)\n",
    "\n",
    "print(\"Found\", len(city_links), \"city links\")\n",
    "\n",
    "all_cities = []\n",
    "for link in city_links:\n",
    "    time.sleep(random.uniform(1, 2))  \n",
    "    r = requests.get(link, headers=headers)\n",
    "    s = BeautifulSoup(r.content, \"html.parser\")\n",
    "\n",
    "    city = s.find(\"h1\").get_text(strip=True).replace(\"Weather\", \"\").strip()\n",
    "    temp = s.find(\"div\", class_=\"h2\").get_text(strip=True)\n",
    "    cond = s.find(\"div\", id=\"qlook\").p.get_text(strip=True)\n",
    "\n",
    "    all_cities.append([city, temp, cond])\n",
    "\n",
    "df = pd.DataFrame(all_cities, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
    "df.to_csv(\"weather.csv\", index=False)\n",
    "\n",
    "print(\"Scraped weather data for\", len(df), \"cities.\")\n",
    "print(df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
