{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eac46024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping finished! Total books: 1000\n",
      "                                                 Title   Price Availability  \\\n",
      "308                   Eligible (The Austen Project #4)  £27.09     In stock   \n",
      "436  If I Gave You God's Phone Number....: Searchin...  £20.91     In stock   \n",
      "799              One for the Money (Stephanie Plum #1)  £32.87     In stock   \n",
      "691                                       'Salem's Lot  £49.56     In stock   \n",
      "508              The Bourne Identity (Jason Bourne #1)  £42.78     In stock   \n",
      "\n",
      "    Star Rating  \n",
      "308       Three  \n",
      "436         One  \n",
      "799         Two  \n",
      "691        Four  \n",
      "508        Four  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "URL_PATTERN = \"https://books.toscrape.com/catalogue/page-{}.html\"\n",
    "\n",
    "all_books = []\n",
    "\n",
    "for pg in range(1, 51): \n",
    "    page_url = URL_PATTERN.format(pg)\n",
    "    response = requests.get(page_url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Page {pg} could not be loaded.\")\n",
    "        break\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    for book in soup.select(\"article.product_pod\"):\n",
    "        book_title = book.h3.a[\"title\"]\n",
    "        book_price = book.select_one(\"p.price_color\").text.strip()\n",
    "        stock_status = book.select_one(\"p.instock.availability\").get_text(strip=True)\n",
    "        \n",
    "        rating_tag = book.select_one(\"p.star-rating\")\n",
    "        star_text = [c for c in rating_tag[\"class\"] if c != \"star-rating\"][0]\n",
    "\n",
    "        all_books.append({\n",
    "            \"Title\": book_title,\n",
    "            \"Price\": book_price,\n",
    "            \"Availability\": stock_status,\n",
    "            \"Star Rating\": star_text\n",
    "        })\n",
    "df = pd.DataFrame(all_books)\n",
    "df.to_csv(\"books.csv\", index=False)\n",
    "\n",
    "print(\"Scraping finished! Total books:\", len(df))\n",
    "print(df.sample(5)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f46044e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded IMDb Top 250 from CSV\n",
      "Empty DataFrame\n",
      "Columns: [Rank, Title, Year, Rating]\n",
      "Index: []\n",
      "\n",
      "Total movies scraped: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.get(\"https://www.imdb.com/chart/top/\")\n",
    "time.sleep(3)\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "movies = []\n",
    "rows = soup.select(\"li.ipc-metadata-list-summary-item\")\n",
    "\n",
    "for rank, row in enumerate(rows, start=1):\n",
    "    title_tag = row.select_one(\"h3\")\n",
    "    title = title_tag.text.replace(str(rank)+\".\", \"\").strip()\n",
    "    year = row.select_one(\"span.ipc-title__subtext\").text.strip(\"()\")\n",
    "    rating = row.select_one(\"span.ipc-rating-star--rating\").text\n",
    "    movies.append([rank, title, year, rating])\n",
    "\n",
    "df_imdb = pd.DataFrame(movies, columns=[\"Rank\", \"Title\", \"Year\", \"Rating\"])\n",
    "df_imdb.to_csv(\"imdb_top250.csv\", index=False)\n",
    "df_imdb.head()\n",
    "df_loaded = pd.read_csv(\"imdb_top250.csv\")\n",
    "\n",
    "print(\"Successfully loaded IMDb Top 250 from CSV\")\n",
    "print(df_loaded.head())     # show first 5 rows\n",
    "print(\"\\nTotal movies scraped:\", len(df_loaded))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c963b15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Condition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [City, Temperature, Condition]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.timeanddate.com/weather/\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "\n",
    "cities = []\n",
    "rows = soup.select(\"table tbody tr\")\n",
    "\n",
    "for row in rows:\n",
    "    city_tag = row.find(\"a\")\n",
    "    if not city_tag:\n",
    "        continue\n",
    "    city = city_tag.text\n",
    "    temp = row.find_all(\"td\")[1].text.strip()\n",
    "    condition = row.find_all(\"td\")[2].text.strip()\n",
    "    cities.append([city, temp, condition])\n",
    "\n",
    "df_weather = pd.DataFrame(cities, columns=[\"City\", \"Temperature\", \"Condition\"])\n",
    "df_weather.to_csv(\"weather.csv\", index=False)\n",
    "df_weather.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
